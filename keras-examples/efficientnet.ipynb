{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9394f27e-348d-4ecd-8ed4-f6499a8a36c7",
   "metadata": {},
   "source": [
    "## Keras EfficientNet example\n",
    "[Link to tutorial](https://keras.io/examples/vision/image_classification_efficientnet_fine_tuning/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34aa4c03-a89a-45b6-885b-f43eb7e6acac",
   "metadata": {},
   "source": [
    "Content\n",
    "1. [AWS BucketSetup](#1.-AWS-Bucket-setup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c8fbe69-4ab8-4459-83f5-22f5dbc12159",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib as plt\n",
    "plt.rcParams['figure.figsize'] = (10, 10)\n",
    "plt.rcParams['figure.dpi'] = 72"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7db792ab-bd1c-4c7f-9cc6-3d93756dcb0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "model = EfficientNetB0(weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcd13446-8fac-4fd3-a06b-9847f38d3872",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install --upgrade sagemaker\n",
    "%pip install tensorflow_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77d15b92-e21e-4f5e-ba20-521892367eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import glob\n",
    "import boto3\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role, image_uris, model_uris, script_uris, hyperparameters\n",
    "from sagemaker.s3 import S3Downloader\n",
    "from sagemaker.utils import name_from_base\n",
    "from sagemaker.session import Session\n",
    "from sagemaker.estimator import Estimator\n",
    "from sagemaker.analytics import TrainingJobAnalytics\n",
    "from sagemaker import exceptions\n",
    "from sagemaker.tuner import (\n",
    "    HyperparameterTuner,\n",
    "    ContinuousParameter,\n",
    "    IntegerParameter,\n",
    "    CategoricalParameter,\n",
    ")\n",
    "from botocore.exceptions import ClientError\n",
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a13cb1c-598d-4b56-a7db-155eae862757",
   "metadata": {},
   "source": [
    "## 1. AWS Bucket setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8351b80d-0cd3-4373-9aab-bdff759f3e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sagemaker_session = sagemaker.Session()\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "role = sagemaker.get_execution_role()\n",
    "region = boto3.Session().region_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92424bb1-50fa-4774-8c2d-db1673664638",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download data for preprocessing\n",
    "solution_bucket = \"sagemaker-solutions-prod\"\n",
    "solution_name = \"sagemaker-defect-detection/1.4.0\"\n",
    "\n",
    "original_bucket = f\"s3://{solution_bucket}-{region}/{solution_name}\"\n",
    "original_data_prefix = \"data/NEU-DET.zip\"\n",
    "original_data = f\"{original_bucket}/{original_data_prefix}\"\n",
    "print(\"original data: \")\n",
    "S3Downloader.list(original_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8936264a-cc07-464c-bc8e-647090244fb7",
   "metadata": {},
   "source": [
    "## Write the output of the model predictions in key with the datetime in it.\n",
    "I couldn't manage to save the input data in S3. So we load it in again each run.\n",
    "Probably should have loaded it ecs, unzipped it and copied the output to S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac5441b0-08fa-4b99-afe2-8f1f8c19fce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_prefix = 'keras-examples'\n",
    "output_files_prefix = name_from_base('efficientnet-classification')\n",
    "\n",
    "\n",
    "s3_output_location = f\"s3://{bucket}/{topic_prefix}/{output_files_prefix}/output\"\n",
    "print(s3_output_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56feb95e-330b-4ca3-a71a-440c65c1afbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "dataset_name = \"stanford_dogs\"\n",
    "(ds_train, ds_test), ds_info = tfds.load(\n",
    "    dataset_name, split=[\"train\", \"test\"], with_info=True, as_supervised=True\n",
    ")\n",
    "NUM_CLASSES = ds_info.features[\"label\"].num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f3921e-a619-41e7-8f76-3704af61cbda",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Keras example\n",
    "# input shape of (224, 224, 3)\n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "model = EfficientNetB0(weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e8f21c2-73cc-4973-8b84-98f2dd77c832",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = EfficientNetB0(include_top=False, weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06eeea64-50f3-432f-a72e-c1c76ef24438",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = EfficientNetB0(weights='imagenet', drop_connect_rate=0.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41a4a295-cbb4-4d83-80f1-aab2f863f57f",
   "metadata": {},
   "source": [
    "## Stanford dogs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ed40def-1983-4dce-9604-2db7f28cfeda",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bc5aab6-0a3f-426f-b70e-d84ddecede42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "try:\n",
    "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver.connect()\n",
    "    print(\"Device:\", tpu.master())\n",
    "    strategy = tf.distribute.TPUStrategy(tpu)\n",
    "except ValueError:\n",
    "    print(\"Not connected to a TPU runtime. Using CPU/GPU strategy\")\n",
    "    strategy = tf.distribute.MirroredStrategy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e46a63-0795-47a0-a519-9410a64bc0bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "size = (IMG_SIZE, IMG_SIZE)\n",
    "ds_train = ds_train.map(lambda image, label: (tf.image.resize(image, size), label))\n",
    "ds_test = ds_test.map(lambda image, label: (tf.image.resize(image, size), label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8529fecd-579e-4939-ae7d-dcae5814110e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def format_label(label):\n",
    "    # this is a method on tfds.features.ClassLabel https://www.tensorflow.org/datasets/api_docs/python/tfds/features/ClassLabel#int2str\n",
    "    string_label = label_info.int2str(label)\n",
    "    return string_label.split(\"-\")[1]\n",
    "\n",
    "\n",
    "label_info = ds_info.features[\"label\"]\n",
    "for i, (image, label) in enumerate(ds_train.take(9)):\n",
    "    ax = plt.subplot(3, 3, i + 1)\n",
    "    plt.imshow(image.numpy().astype(\"uint8\"))\n",
    "    plt.title(\"{}\".format(format_label(label)))\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b8c7ce-a072-4332-9fa5-d4a4468961d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data augmentation step\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "img_augmentation = Sequential(\n",
    "    [\n",
    "        layers.RandomRotation(factor=0.15),\n",
    "        layers.RandomTranslation(height_factor=0.1, width_factor=0.1),\n",
    "        layers.RandomFlip(),\n",
    "        layers.RandomContrast(factor=0.1),\n",
    "    ],\n",
    "    name=\"img_augmentation\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14044b5d-7026-4a35-b3ae-babc0e96e16a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for image, label in ds_train.take(1):\n",
    "    for i in range(9):\n",
    "        ax = plt.subplot(3, 3, i + 1)\n",
    "        # I thnk this is done to add an outer batch dimension.\n",
    "        # Sometimes tf.nn.conv2d (or the tf network being used requires certain dimensionality)\n",
    "        aug_img = img_augmentation(tf.expand_dims(image, axis=0))\n",
    "        plt.imshow(aug_img[0].numpy().astype(\"uint8\"))\n",
    "        plt.title(\"{}\".format(format_label(label)))\n",
    "        plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf90e6d0-9c46-40f8-8f43-d3ce0e851586",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot / categorical encoding\n",
    "def input_preprocess(image, label):\n",
    "    label = tf.one_hot(label, NUM_CLASSES)\n",
    "    return image, label\n",
    "\n",
    "\n",
    "ds_train = ds_train.map(\n",
    "    input_preprocess, num_parallel_calls=tf.data.AUTOTUNE\n",
    ")\n",
    "ds_train = ds_train.batch(batch_size=batch_size, drop_remainder=True)\n",
    "ds_train = ds_train.prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "ds_test = ds_test.map(input_preprocess)\n",
    "ds_test = ds_test.batch(batch_size=batch_size, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "374b6d11-8df6-4f58-bac2-beadbbcb64f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "\n",
    "with strategy.scope():\n",
    "    inputs = layers.Input(shape=(IMG_SIZE, IMG_SIZE, 3))\n",
    "    x = img_augmentation(inputs)\n",
    "    outputs = EfficientNetB0(include_top=True, weights=None, classes=NUM_CLASSES)(x)\n",
    "\n",
    "    model = tf.keras.Model(inputs, outputs)\n",
    "    model.compile(\n",
    "        optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"]\n",
    "    )\n",
    "\n",
    "model.summary()\n",
    "\n",
    "epochs = 40  # @param {type: \"slider\", min:10, max:100}\n",
    "hist = model.fit(ds_train, epochs=epochs, validation_data=ds_test, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "519f87b5-1411-4df2-a27e-55b2e79f1698",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow2_p38",
   "language": "python",
   "name": "conda_tensorflow2_p38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
